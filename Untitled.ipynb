{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caliberation in Progress!\n",
      "Caliberation Complete!\n",
      "Current SPF (seconds per frame) is 33.27 ms\n",
      "drowsy limit: 45.087289287202346, false blink limit: 4.508728928720235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vaibhav/anaconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/vaibhav/anaconda3/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-1-5da35a153b27>\", line 61, in soundAlert\n",
      "    playsound.playsound(path)\n",
      "  File \"/home/vaibhav/anaconda3/lib/python3.7/site-packages/playsound.py\", line 91, in _playsoundNix\n",
      "    import gi\n",
      "ModuleNotFoundError: No module named 'gi'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TODO:\n",
    "    - Improve face landmark detection. Probably caused due to lighting changes. Eliminate the effect of lightinh with minimal computation.\n",
    "      Solved by histogram equalization\n",
    "\n",
    "    - Stabilize face landmark points\n",
    "\n",
    "    - Gaze direction\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import dlib\n",
    "import sys\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "from threading import Thread\n",
    "import playsound\n",
    "import queue\n",
    "# from light_variability import adjust_gamma\n",
    "\n",
    "FACE_DOWNSAMPLE_RATIO = 1.5\n",
    "RESIZE_HEIGHT = 460\n",
    "\n",
    "thresh = 0.27\n",
    "modelPath = \"models/shape_predictor_70_face_landmarks.dat\"\n",
    "sound_path = \"alarm.wav\"\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(modelPath)\n",
    "\n",
    "leftEyeIndex = [36, 37, 38, 39, 40, 41]\n",
    "rightEyeIndex = [42, 43, 44, 45, 46, 47]\n",
    "\n",
    "blinkCount = 0\n",
    "drowsy = 0\n",
    "state = 0\n",
    "blinkTime = 0.15 #150ms\n",
    "drowsyTime = 1.5  #1200ms\n",
    "ALARM_ON = False\n",
    "GAMMA = 1.5\n",
    "threadStatusQ = queue.Queue()\n",
    "\n",
    "invGamma = 1.0/GAMMA\n",
    "table = np.array([((i / 255.0) ** invGamma) * 255 for i in range(0, 256)]).astype(\"uint8\")\n",
    "\n",
    "def gamma_correction(image):\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "def histogram_equalization(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return cv2.equalizeHist(gray) \n",
    "\n",
    "def soundAlert(path, threadStatusQ):\n",
    "    while True:\n",
    "        if not threadStatusQ.empty():\n",
    "            FINISHED = threadStatusQ.get()\n",
    "            if FINISHED:\n",
    "                break\n",
    "        playsound.playsound(path)\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "\n",
    "    return ear\n",
    "\n",
    "\n",
    "def checkEyeStatus(landmarks):\n",
    "    mask = np.zeros(frame.shape[:2], dtype = np.float32)\n",
    "    \n",
    "    hullLeftEye = []\n",
    "    for i in range(0, len(leftEyeIndex)):\n",
    "        hullLeftEye.append((landmarks[leftEyeIndex[i]][0], landmarks[leftEyeIndex[i]][1]))\n",
    "\n",
    "    cv2.fillConvexPoly(mask, np.int32(hullLeftEye), 255)\n",
    "\n",
    "    hullRightEye = []\n",
    "    for i in range(0, len(rightEyeIndex)):\n",
    "        hullRightEye.append((landmarks[rightEyeIndex[i]][0], landmarks[rightEyeIndex[i]][1]))\n",
    "\n",
    "\n",
    "    cv2.fillConvexPoly(mask, np.int32(hullRightEye), 255)\n",
    "\n",
    "    # lenLeftEyeX = landmarks[leftEyeIndex[3]][0] - landmarks[leftEyeIndex[0]][0]\n",
    "    # lenLeftEyeY = landmarks[leftEyeIndex[3]][1] - landmarks[leftEyeIndex[0]][1]\n",
    "\n",
    "    # lenLeftEyeSquared = (lenLeftEyeX ** 2) + (lenLeftEyeY ** 2)\n",
    "    # eyeRegionCount = cv2.countNonZero(mask)\n",
    "\n",
    "    # normalizedCount = eyeRegionCount/np.float32(lenLeftEyeSquared)\n",
    "\n",
    "    #############################################################################\n",
    "    leftEAR = eye_aspect_ratio(hullLeftEye)\n",
    "    rightEAR = eye_aspect_ratio(hullRightEye)\n",
    "\n",
    "    ear = (leftEAR + rightEAR) / 2.0\n",
    "    #############################################################################\n",
    "\n",
    "    eyeStatus = 1          # 1 -> Open, 0 -> closed\n",
    "    if (ear < thresh):\n",
    "        eyeStatus = 0\n",
    "\n",
    "    return eyeStatus  \n",
    "\n",
    "def checkBlinkStatus(eyeStatus):\n",
    "    global state, blinkCount, drowsy\n",
    "    if(state >= 0 and state <= falseBlinkLimit):\n",
    "        if(eyeStatus):\n",
    "            state = 0\n",
    "\n",
    "        else:\n",
    "            state += 1\n",
    "\n",
    "    elif(state >= falseBlinkLimit and state < drowsyLimit):\n",
    "        if(eyeStatus):\n",
    "            blinkCount += 1 \n",
    "            state = 0\n",
    "\n",
    "        else:\n",
    "            state += 1\n",
    "\n",
    "\n",
    "    else:\n",
    "        if(eyeStatus):\n",
    "            state = 0\n",
    "            drowsy = 1\n",
    "            blinkCount += 1\n",
    "\n",
    "        else:\n",
    "            drowsy = 1\n",
    "\n",
    "def getLandmarks(im):\n",
    "    imSmall = cv2.resize(im, None, \n",
    "                            fx = 1.0/FACE_DOWNSAMPLE_RATIO, \n",
    "                            fy = 1.0/FACE_DOWNSAMPLE_RATIO, \n",
    "                            interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "    rects = detector(imSmall, 0)\n",
    "    if len(rects) == 0:\n",
    "        return 0\n",
    "\n",
    "    newRect = dlib.rectangle(int(rects[0].left() * FACE_DOWNSAMPLE_RATIO),\n",
    "                            int(rects[0].top() * FACE_DOWNSAMPLE_RATIO),\n",
    "                            int(rects[0].right() * FACE_DOWNSAMPLE_RATIO),\n",
    "                            int(rects[0].bottom() * FACE_DOWNSAMPLE_RATIO))\n",
    "\n",
    "    points = []\n",
    "    [points.append((p.x, p.y)) for p in predictor(im, newRect).parts()]\n",
    "    return points\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "for i in range(10):\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "totalTime = 0.0\n",
    "validFrames = 0\n",
    "dummyFrames = 100\n",
    "\n",
    "print(\"Caliberation in Progress!\")\n",
    "while(validFrames < dummyFrames):\n",
    "    validFrames += 1\n",
    "    t = time.time()\n",
    "    ret, frame = capture.read()\n",
    "    height, width = frame.shape[:2]\n",
    "    IMAGE_RESIZE = np.float32(height)/RESIZE_HEIGHT\n",
    "    frame = cv2.resize(frame, None, \n",
    "                        fx = 1/IMAGE_RESIZE, \n",
    "                        fy = 1/IMAGE_RESIZE, \n",
    "                        interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "    # adjusted = gamma_correction(frame)\n",
    "    adjusted = histogram_equalization(frame)\n",
    "\n",
    "    landmarks = getLandmarks(adjusted)\n",
    "    timeLandmarks = time.time() - t\n",
    "\n",
    "    if landmarks == 0:\n",
    "        validFrames -= 1\n",
    "        cv2.putText(frame, \"Unable to detect face, Please check proper lighting\", (10, 30), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "        cv2.putText(frame, \"or decrease FACE_DOWNSAMPLE_RATIO\", (10, 50), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "        cv2.imshow(\"Blink Detection Demo\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            sys.exit()\n",
    "\n",
    "    else:\n",
    "        totalTime += timeLandmarks\n",
    "        # cv2.putText(frame, \"Caliberation in Progress\", (200, 30), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "        # cv2.imshow(\"Blink Detection Demo\", frame)\n",
    "        \n",
    "    # if cv2.waitKey(1) & 0xFF == 27:\n",
    "    #         sys.exit()\n",
    "\n",
    "print(\"Caliberation Complete!\")\n",
    "\n",
    "spf = totalTime/dummyFrames\n",
    "print(\"Current SPF (seconds per frame) is {:.2f} ms\".format(spf * 1000))\n",
    "\n",
    "drowsyLimit = drowsyTime/spf\n",
    "falseBlinkLimit = blinkTime/spf\n",
    "print(\"drowsy limit: {}, false blink limit: {}\".format(drowsyLimit, falseBlinkLimit))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    vid_writer = cv2.VideoWriter('output-low-light-2.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 15, (frame.shape[1],frame.shape[0]))\n",
    "    while(1):\n",
    "        try:\n",
    "            t = time.time()\n",
    "            ret, frame = capture.read()\n",
    "            height, width = frame.shape[:2]\n",
    "            IMAGE_RESIZE = np.float32(height)/RESIZE_HEIGHT\n",
    "            frame = cv2.resize(frame, None, \n",
    "                                fx = 1/IMAGE_RESIZE, \n",
    "                                fy = 1/IMAGE_RESIZE, \n",
    "                                interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "            # adjusted = gamma_correction(frame)\n",
    "            adjusted = histogram_equalization(frame)\n",
    "\n",
    "            landmarks = getLandmarks(adjusted)\n",
    "            if landmarks == 0:\n",
    "                validFrames -= 1\n",
    "                cv2.putText(frame, \"Unable to detect face, Please check proper lighting\", (10, 30), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                cv2.putText(frame, \"or decrease FACE_DOWNSAMPLE_RATIO\", (10, 50), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                cv2.imshow(\"Blink Detection Demo\", frame)\n",
    "                if cv2.waitKey(1) & 0xFF == 27:\n",
    "                    break\n",
    "                continue\n",
    "\n",
    "            eyeStatus = checkEyeStatus(landmarks)\n",
    "            checkBlinkStatus(eyeStatus)\n",
    "\n",
    "            for i in range(0, len(leftEyeIndex)):\n",
    "                cv2.circle(frame, (landmarks[leftEyeIndex[i]][0], landmarks[leftEyeIndex[i]][1]), 1, (0, 0, 255), -1, lineType=cv2.LINE_AA)\n",
    "\n",
    "            for i in range(0, len(rightEyeIndex)):\n",
    "                cv2.circle(frame, (landmarks[rightEyeIndex[i]][0], landmarks[rightEyeIndex[i]][1]), 1, (0, 0, 255), -1, lineType=cv2.LINE_AA)\n",
    "\n",
    "            if drowsy:\n",
    "                cv2.putText(frame, \"! ! ! DROWSINESS ALERT ! ! !\", (70, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                if not ALARM_ON:\n",
    "                    ALARM_ON = True\n",
    "                    threadStatusQ.put(not ALARM_ON)\n",
    "                    thread = Thread(target=soundAlert, args=(sound_path, threadStatusQ,))\n",
    "                    thread.setDaemon(True)\n",
    "                    thread.start()\n",
    "\n",
    "            else:\n",
    "                cv2.putText(frame, \"Blinks : {}\".format(blinkCount), (460, 80), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 2, cv2.LINE_AA)\n",
    "                # (0, 400)\n",
    "                ALARM_ON = False\n",
    "\n",
    "\n",
    "            cv2.imshow(\"Blink Detection Demo\", frame)\n",
    "            vid_writer.write(frame)\n",
    "\n",
    "            k = cv2.waitKey(1) \n",
    "            if k == ord('r'):\n",
    "                state = 0\n",
    "                drowsy = 0\n",
    "                ALARM_ON = False\n",
    "                threadStatusQ.put(not ALARM_ON)\n",
    "\n",
    "            elif k == 27:\n",
    "                break\n",
    "\n",
    "            # print(\"Time taken\", time.time() - t)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    capture.release()\n",
    "    vid_writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
